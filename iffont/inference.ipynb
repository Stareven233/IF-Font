{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "ROOT = Path(r'path/to/checkpoint')\n",
    "H5_PATH = r'path/to/if_fonts.h5'\n",
    "FONT_DIR = Path(r'path/to/fonts')\n",
    "BASE_FONT = (FONT_DIR / 'choose/any/one.ttf').as_posix()\n",
    "CKPT_PATH = ROOT / 'ckpt/last.ckpt'\n",
    "LOG_PATH = ROOT / 'tb_logs/version_0'\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "from PIL import ImageFont\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import trange as tqdm_range\n",
    "\n",
    "sys.path.append('.')\n",
    "from util import utils\n",
    "utils.setup_seed(23)\n",
    "from util import importtool\n",
    "from data import cn, valid_characters\n",
    "from data.datasets_h5 import IFFontDataset\n",
    "from data.adapter import pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [OmegaConf.load(c) for c in LOG_PATH.rglob('*.yaml')]\n",
    "config = OmegaConf.merge(*config)\n",
    "# parser.link_arguments\n",
    "n_embd = config.model.init_args.gpt.init_args.config.init_args.n_embd\n",
    "config.model.init_args.moco_wrapper.init_args.c_out = n_embd\n",
    "config.model.init_args.ids_enc.init_args.n_embd = n_embd\n",
    "\n",
    "model = importtool.instantiate_from_config_recursively(config.model)\n",
    "model.init_from_ckpt(CKPT_PATH)\n",
    "model = model.eval().to(DEVICE)\n",
    "model.on_predict_start()\n",
    "ids_enc = model.ids_encoder\n",
    "counter = utils.counter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x:torch.Tensor, d_range=(-1, 1)):\n",
    "  low, high = d_range\n",
    "  x = torch.clamp(x, low, high)\n",
    "  x = (x - low) / (high - low)\n",
    "  return x\n",
    "\n",
    "\n",
    "def sample(*input_tuple, use_tqdm=True, sample=False, top_k=None):\n",
    "  g_idx = model.sample(\n",
    "    *input_tuple,\n",
    "    steps=input_tuple[1].shape[2],\n",
    "    temperature=1.0,\n",
    "    sample=sample,\n",
    "    top_k=top_k,\n",
    "    step_range=tqdm_range if use_tqdm else range,\n",
    "  )\n",
    "  g: torch.Tensor = model.adapter.decode_raw(g_idx)\n",
    "  g = normalize(g, (-1, 1))\n",
    "  return g\n",
    "\n",
    "\n",
    "def infer_dataset(dataloader):\n",
    "  x_idx, c_idx, *ch_info = model.get_data(next(iter(dataloader)))[:-2]\n",
    "  x_idx, c_idx = x_idx.to(model.device), c_idx.to(model.device)\n",
    "  x, c = model.adapter.decode_raw(x_idx), model.adapter.decode_raw(c_idx[:, 0])\n",
    "  # g = sample(x_idx[:, :0], c_idx, ch_info, sample=True, top_k=100)  # 按概率采样\n",
    "  g = sample(x_idx[:, :0], c_idx, *ch_info)  # 最大概率采样（确定性采样）\n",
    "  imgs = torch.stack((x, c, g), dim=0)\n",
    "  utils.draw_batch_images(*imgs)\n",
    "\n",
    "\n",
    "def infer_create(font_list, ids_list=None, chs=None, ref_chs=None, size=128, save='temp', layout='row'):\n",
    "  assert layout in ('row', 'column')\n",
    "  assert (ids_enc.input_mode=='ch' and chs is not None) or (ids_enc.input_mode=='ids' and ids_list is not None)\n",
    "  data_list = []\n",
    "  ref_chs = list(ref_chs or valid_characters.train_ch)\n",
    "\n",
    "  for i, font in enumerate(font_list):\n",
    "    f = ImageFont.truetype(font, size=size)\n",
    "    if chs is not None:\n",
    "      ch = chs[i]\n",
    "      x_ids = ch\n",
    "      x_img = pil_to_tensor(utils.draw_single_char(ch, f, size))\n",
    "      print('ch@', ch, [''.join(x) for x in ids_enc.query_ids(ch)])\n",
    "  \n",
    "    if ids_list is not None:\n",
    "      x_ids = ids_list[i]\n",
    "      x_img = utils.draw_text_img(x_ids, size=50, canvas_size=size, font=BASE_FONT)[0] if chs is None else x_img\n",
    "      ch = (chs is not None and locals().get('ch')) or x_ids\n",
    "      x_ids = (x if x in ids_enc.vocabulary_map else ids_enc.query_ids(x)[0] for x in x_ids)\n",
    "      x_ids = utils.chain_sequence(*x_ids)\n",
    "      print('ids@', ch, ''.join(x_ids))\n",
    "\n",
    "    c_idx, c_ids = [], []\n",
    "    random.shuffle(ref_chs)\n",
    "    for ch in ref_chs:\n",
    "      if len(c_idx) >= config.data.init_args.num_refs:\n",
    "        break\n",
    "      c_img = pil_to_tensor(utils.draw_single_char(ch, f, size))\n",
    "      if c_img is None:\n",
    "        print(f'character {ch} not in font {font} !')\n",
    "        continue\n",
    "      c_ids.append(ch)\n",
    "      c_idx.append(model.adapter.encode(c_img))\n",
    "\n",
    "    c_idx = torch.stack(c_idx, dim=0)\n",
    "    data_list.append({\n",
    "      'x': x_img,\n",
    "      'c': c_img,\n",
    "      'c_idx': c_idx,\n",
    "      'x_ids': x_ids,\n",
    "      'c_ids': c_ids,\n",
    "    })\n",
    "  d = IFFontDataset.collate(data_list)\n",
    "  c_idx = d['c_idx']\n",
    "  c = d.pop('c').to(model.device)\n",
    "  x = d.pop('x').to(model.device)\n",
    "  print(f'c_ids = {d[\"c_ids\"]}')\n",
    "  g = sample(c_idx[:, 0, :0], c_idx, d['x_ids'], d['c_ids'])\n",
    "  imgs = torch.stack((x, c, g), dim=0)\n",
    "  if save is not None:\n",
    "    save = (ROOT / f'create_samples/{save}.png')\n",
    "    save.parent.mkdir(exist_ok=True)\n",
    "  if layout == 'column':\n",
    "    imgs = imgs.permute(1, 0, 2, 3, 4)\n",
    "  utils.draw_batch_images(*imgs, n=imgs.shape[1], save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IDX = 0  # 0-3: ('train', 'train') - ('train', 'val') - ('val', 'train') - ('val', 'val') (font - ch)\n",
    "_SPLIT = ('train', 'val')\n",
    "_INFER_MODE = 1\n",
    "\n",
    "match _INFER_MODE:\n",
    "  case 1:\n",
    "    dataset = IFFontDataset(H5_PATH, _SPLIT[_IDX>>1&0b01], _SPLIT[_IDX&0b01], num_refs=config.data.init_args.num_refs)\n",
    "    dataloader = DataLoader(\n",
    "      dataset,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      shuffle=True,\n",
    "      collate_fn=IFFontDataset.collate,\n",
    "      num_workers=0,\n",
    "      pin_memory=True,\n",
    "    )\n",
    "    ids_enc.input_mode = 'ch'\n",
    "    infer_dataset(dataloader)\n",
    "\n",
    "  case 2:\n",
    "    # ids_enc.input_mode = 'ch'\n",
    "    # ch = '夏色祭茄茫晤'\n",
    "    ids_enc.input_mode = 'ids'\n",
    "    ref_chs=None\n",
    "    ids_map = {\n",
    "      '俣': '⿰亻吴', '辻': '⿺辶十', '萩': '⿱艹秋', '笹': '⿱𥫗世', '凧': '⿵𠘨巾', '粁': '⿰米千', \n",
    "      '込': '⿺辶入', '畑': '⿰火田', '凪': '⿵𠘨止', '雫': '⿱雨下', '丼': '⿴井丶', '畠': '⿱白田', \n",
    "    }\n",
    "    ch = tuple(ids_map.keys())\n",
    "    ids = tuple(ids_map.values())\n",
    "\n",
    "    font = (BASE_FONT, )\n",
    "    infer_create(font * len(ch or ids), ids_list=ids, chs=ch, ref_chs=ref_chs, save=str(counter()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
